% \documentclass[twoside,9pt]{extarticle}
    \documentclass[12pt,twoside]{article}
        \usepackage{jmlda}
        
        \usepackage{color}% Include colors for document elements
\newcommand\red[1]{{\color{red}#1}}
\newcommand\green[1]{{\color{green}#1}}
\newcommand\blue[1]{{\color{blue}#1}}

        \usepackage{listings}
        \usepackage{caption}
        %\DeclareCaptionFont{white}{\color{white}}
        %\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
        %\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
        %%\NOREVIEWERNOTES
        
        % \newenvironment{coderes}%
        %     {\medskip\tabcolsep=0pt\begin{tabular}{>{\small}l@{\quad}|@{\quad}l}}%
        %     {\end{tabular}\medskip}
        
        \begin{document}
        
        \title{On conformational changes of proteins using collective motions in torsion angles and L1 regularization}
        \author{Ryabinina~R.\,B., Emtsev~D.\,I.}
            [Ryabinina~R.\,B.$^1$, 
            Emtsev~D.\,I.$^2$ ]
        \email{$^1$ ryabinina.rb@phystech.edu 
               $^2$ daniil.emcev.ru@yandex.ru 
               }
        \organization{$^{1\,2}$MIPT}
        
        \abstract{
          Investigation of conformational transitions in proteins is an important and well-studied problem in structural bioinformatics with applications ranged from drug design to understanding hidden effects in the structural data. 
            A related important and open question in computational structural bioinformatics is how to efficiently represent transitions between protein structures. 
            Here, we address the problem of how a sparse subset of collective coordinates in the torsion subspace can describe functional conformational changes in proteins. 	
            The solution strategy consists in determining the change of torsion angles through the fit of the linearized change of Cartesian coordinates. 
            However, if the fit is not regularized, the structures produced in this approach demonstrate the deviation of several Angstroms from the targets. 
            Rescaled ridge regression (RRR) has been recently introduced to regularize multi-dimensional regressions with correlated explanatory variables. 
            The resulting torsional conformational changes generate conformations that are much more similar to the target conformations.
%            This approach also and they are better correlated with the thermal fluctuations of torsion angles and with the normal modes predicted by the TNM than the torsional conformational changes obtained through ordinary regression. 
            This approach also predicts atomic thermal fluctuations that are better correlated with the ones measured experimentally.
            Our goal is to find a solution of a ridge regression problem with an L1 regularization constraint using the LASSO formulation. 
            Not much has been done in the torsional angle subspace (internal coordinates) for this problem and nearly nothing has been done using L1 regularization.
        }
        \bigskip
       \maketitle
      % \maketitleSecondary
        \bigskip
        \bigskip
        \section{Introduction}
        
        There is growing interest in the investigation of the intrinsic dynamic properties of proteins in their native state. They play a key role in ensuring proper functional activity, notably for catalysis, allosteric regulation or molecular recognition. 
        Despite recent progress, the experimental studies of protein dynamics remain rather challenging, and computational methods often constitute valuable alternatives. 
        It is often assumed that torsion angles are the natural degrees of freedom for describing protein motions \cite{pmid:20867208} ,
since bond lengths and bond angles are strongly constrained by covalent forces. Because of this reason,
several computational methods have been developed to study protein dynamics in torsion angle space. 
There is a desperate need of systems to predict dynamic motions. 
Elastic network models (ENMs) \cite{PhysRevLett.77.1905, ATILGAN2001505, BAHAR2005586} are becoming increasingly popular since they provide detailed analytic predictions of native protein dynamics at a very reasonable computational cost. 

Ridge regression is one of the most common methods for regularising fits with many variables.  It relies heavily on the choice of an adequate value for the ridge (regularization) parameter. Its optimal value is generally unknown, and several criteria have been proposed for its determination. 
For example, the cross-validation technique is the most popular choice for it.
%However, there is no solution how to systematically determine the optimal value of this parameter. 

There are two popular techniques, Tikhonov regularization and ridge regularization which deal with collinearity in multivariate regression. 
Inspired by successful use of the Lasso method, we propose a LASSO formulation with the direction vectors reconstructed from the internal coordinates. 
We are using as a base the TNM model \cite{pmid:20867208}.  
We received better  computing using RMSD measure between the prediction and the solution on several benchmarks.
\bigskip
\bigskip

Our aim here is threefold: 
\begin{enumerate}
\item construct a novel approach with the Lasso regularization;
 \item  apply this procedure for fitting the B-factors with predicted internal and rigid-body motions, in order to properly calibrate models of protein dynamics and to infer the respective amplitudes of the fluctuations dynamics and to infer the respective amplitudes of the fluctuations;
  \item  compare results with the previous methods
\end{enumerate}
%(1) construct a novel approach with the Lasso regularization;
 %(2) apply this procedure for fitting the B-factors with predicted internal and rigid-body motions, in order to properly calibrate models of protein dynamics and to infer the respective amplitudes of the fluctuations dynamics and to infer the respective amplitudes of the fluctuations;
  %(3) compare results with the previous methods
  

  
  Compared to the classical variable selection methods, such as subset selection, the LASSO method has two advantages. First, the selection process in the LASSO is based on continuous trajectories of regression coefficients as functions of the penalty level and hence it is more stable than the subset selection methods. 
  Second, the LASSO method is computationally feasible for high-dimensional data\cite{tibshirani1996regression,RePEc:eee:jmvana:v:132:y:2014:i:C:p:138-150,oai:CiteSeerPSU:302091} .


 
 \section{Methods}
 \subsection{\small{Data sets}}
 %\red{[please, provide 2 test sets. And let's start with the structural transitions (a smaller set)!]} 
 We use a test set of 30 non-redundant monometric proteins which shows the structural transitions.
 
  \subsection{\small{Theory part}}
 Theory part\begin{equation}
\label{eq:linreg}
Y = X\beta + \epsilon
\end{equation}

where $y\ \in \mathbb{R}^n$, $\beta \in \mathbb{R}^p$, and $X \in \mathbb{R}^{n x p}$. We can expand this to $y_i = \sum_{j = 1}^{p}\beta_iX_{ij} + \epsilon_i$, $\forall i = 0,1,...,n$. Here $\beta_j$ are non-random unknown parameters, $X_{ij}$ are non-random and observable, and $\epsilon_i$ are random so $y_i$ are random.\\From multiple linear regression we have the coefficient estimate 
\begin{equation}
\label{eq:betacoef}
\hat{\beta} = (X^TX)^{-1}X^TY
\end{equation}
which we can rewrite as $[(X^TX)^{-1}X^T]^{-1}\hat{\beta} = Y$.\\The LASSO model can be shown in the same form as equation (3) above:
\begin{equation}
\label{eq:LASSO OLS}
(Y-X\beta)^T(Y-X\beta) + \lambda|\beta|_1
\end{equation}
Where $|\beta|_1 = \sum\limits_{j=1}^{p}|\beta|_j$.
 
 \bibliographystyle{ieeetr}
 \bibliography{references}
        \end{document}